import streamlit as st
import joblib
import json, numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from datetime import datetime
# --- MiniLM / lightweight LLM import and availability flag ---
# The following try/except block attempts to import the Hugging Face transformers
# library for use with a small language model (e.g. MiniLM or DistilGPT2).  If
# transformers is not available in the runtime environment, the app will
# gracefully fall back to a deterministic, templateâ€‘based explanation.
try:
    from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline  # type: ignore
    _transformers_available = True
except ImportError:
    _transformers_available = False


# --- 1. ëª¨ë¸ & ë²¡í„°ë¼ì´ì € ë¶ˆëŸ¬ì˜¤ê¸° ---
# load vocab
with open("vocab.json", "r", encoding="utf-8") as f:
    vocab = json.load(f)

# load idf
idf = np.load("idf.npy")

# ì´ˆê¸°í™”
tfidf_vectorizer = TfidfVectorizer(vocabulary=vocab)  # âœ… ë³€ìˆ˜ëª… í†µì¼
tfidf_vectorizer.idf_ = idf

xgb_model = joblib.load("xgbc_nlp_depression_level_model.pkl")


# --- 2. ë¼ë²¨ ë§µ ---
label_map = {0: "ì •ìƒ", 1: "ê²½ë¯¸í•œ ìš°ìš¸ì¦", 2: "ì¤‘ë“±ë„ ìš°ìš¸ì¦"}


# --- LLM ê¸°ë°˜ ì„¤ëª… ìƒì„± í•¨ìˆ˜ ---
def generate_llm_explanation(user_text: str, pred_label: str, llm_model_name: str = "distilgpt2", device: str = "cpu") -> str:
    """
    ì‚¬ìš©ìì˜ ì…ë ¥ ë¬¸ì¥ê³¼ ì˜ˆì¸¡ ë¼ë²¨ì„ ê¸°ë°˜ìœ¼ë¡œ ê°„ë‹¨í•œ ì„¤ëª…ì„ ìƒì„±í•©ë‹ˆë‹¤.
    ê°€ëŠ¥í•œ ê²½ìš° HuggingFace ëª¨ë¸ì„ í™œìš©í•˜ê³ , ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ ê¸°ë³¸ ì„¤ëª…ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    prompt = (
        f"ì‚¬ìš©ìì˜ ì§„ìˆ : {user_text}\n"
        f"ëª¨ë¸ì˜ ì˜ˆì¸¡ ìš°ìš¸ì¦ ì¤‘ì¦ë„: {pred_label}\n"
        "ìœ„ ë‘ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§„ë‹¨ ê²°ê³¼ë¥¼ ì´í•´í•˜ê¸° ì‰½ê²Œ ì„¤ëª…í•´ ì£¼ì„¸ìš”. "
        "ì¹œì ˆí•˜ê³  ê³µê°ê°€ëŠ” ì–´ì¡°ë¡œ í•œêµ­ì–´ë¡œ 3~5ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”."
    )
    # ì‹œë„: transformersë¥¼ ì´ìš©í•œ í…ìŠ¤íŠ¸ ìƒì„±
    if globals().get('_transformers_available'):
        try:
            tokenizer = AutoTokenizer.from_pretrained(llm_model_name)
            model = AutoModelForCausalLM.from_pretrained(llm_model_name)
            generator = pipeline("text-generation", model=model, tokenizer=tokenizer, device=device)
            out = generator(prompt, max_length=len(prompt.split()) + 60, num_return_sequences=1)
            return out[0]["generated_text"]
        except Exception:
            pass
    # fallback ì„¤ëª…
    if pred_label == "ì •ìƒ":
        base = "ëª¨ë¸ ì˜ˆì¸¡ ê²°ê³¼ ì •ìƒ ë²”ì£¼ë¡œ íŒë‹¨ë©ë‹ˆë‹¤. í˜„ì¬ ì…ë ¥í•˜ì‹  ë‚´ìš©ìœ¼ë¡œ ë³´ì•„ í° ìš°ìš¸ ì¦ìƒì€ ë‚˜íƒ€ë‚˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ê¸ì •ì ì¸ ìƒí™œì„ ê³„ì† ìœ ì§€í•˜ì„¸ìš”."
    elif pred_label == "ê²½ë¯¸í•œ ìš°ìš¸ì¦":
        base = "ëª¨ë¸ ì˜ˆì¸¡ ê²°ê³¼ ê²½ë¯¸í•œ ìš°ìš¸ ì¦ìƒì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. ìµœê·¼ì˜ ê°ì • ë³€í™”ë¥¼ ì£¼ì˜ ê¹Šê²Œ ê´€ì°°í•˜ê³ , ìŠ¤íŠ¸ë ˆìŠ¤ë¥¼ ì¤„ì´ëŠ” í™œë™ì„ ì‹œë„í•´ ë³´ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤. í•„ìš”í•˜ë©´ ì£¼ë³€ ì‚¬ëŒë“¤ê³¼ ëŒ€í™”ë¥¼ ë‚˜ëˆ„ê±°ë‚˜ ìƒë‹´ì„ ê³ ë ¤í•´ ë³´ì„¸ìš”."
    else:
        base = "ëª¨ë¸ ì˜ˆì¸¡ ê²°ê³¼ ì¤‘ë“±ë„ ìš°ìš¸ì¦ìœ¼ë¡œ í‰ê°€ë©ë‹ˆë‹¤. ì…ë ¥í•˜ì‹  ë‚´ìš©ì„ ê³ ë ¤í•  ë•Œ ì „ë¬¸ì ì¸ ìƒë‹´ê³¼ ì¹˜ë£Œê°€ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê°€ì¡±ì´ë‚˜ ì¹œêµ¬ì—ê²Œ ë„ì›€ì„ ìš”ì²­í•˜ê³ , ì •ì‹ ê±´ê°•ì˜í•™ê³¼ ì „ë¬¸ì˜ì™€ ìƒë‹´ì„ ê¶Œì¥í•©ë‹ˆë‹¤."
    return base

# --- 3. Streamlit UI ---
st.set_page_config(page_title="ìš°ìš¸ì¦ ì§„ë‹¨ì„œ", layout="centered")
st.title("ğŸ§  ì¸ê³µì§€ëŠ¥ ê¸°ë°˜ ìš°ìš¸ì¦ ì¤‘ì¦ë„ ì˜ˆì¸¡ ì§„ë‹¨ì„œ")

st.markdown("ë³¸ ì†Œí”„íŠ¸ì›¨ì–´ëŠ” ë¶„ë‹¹ì°¨ë³‘ì› ì •ì‹ ê±´ê°•ì˜í•™ê³¼ ì „ë¬¸ì˜ì˜ ìš°ìš¸ì¦ ì§„ë‹¨ ê²½í—˜ì„ ì¸ê³µì§€ëŠ¥ìœ¼ë¡œ í•™ìŠµí•˜ì—¬, ë¬¸ì¥ë§Œìœ¼ë¡œ ìš°ìš¸ì¦ ì¤‘ì¦ë„ë¥¼ ì§„ë‹¨ ì˜ˆì¸¡í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
st.markdown("ì•„ë˜ ì§„ë‹¨ì„œëŠ” ì¸ê³µì§€ëŠ¥ ë¶„ì„ ê²°ê³¼ì´ë©°, **ì •ì‹ ê±´ê°•ì˜í•™ê³¼ ì „ë¬¸ì˜ì˜ ìµœì¢… ì§„ë‹¨ì„ ëŒ€ì²´í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.**")

# ì…ë ¥ì°½
user_input = st.text_area("í˜„ì¬ ëŠë¼ê³  ìˆëŠ” ê°ì •ì„ ë¬¸ì¥ìœ¼ë¡œ ì…ë ¥í•´ë³´ì„¸ìš”.", height=150)

if st.button("ì§„ë‹¨í•˜ê¸°"):
    if not user_input.strip():
        st.warning("âš ï¸ ì…ë ¥ëœ í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        # ì˜ˆì¸¡ í™•ë¥ 
        vec = tfidf_vectorizer.transform([user_input])
        probs = xgb_model.predict_proba(vec)[0]

        # í™•ë¥ ì„ í¼ì„¼íŠ¸(%)ë¡œ ë³€í™˜ í›„ ì†Œìˆ˜ì  1ìë¦¬ê¹Œì§€ ë°˜ì˜¬ë¦¼
        probs_percent = np.round(probs * 100, 1)

        # ê°€ì¥ ë†’ì€ í™•ë¥  í´ë˜ìŠ¤
        pred_idx = int(np.argmax(probs_percent))
        pred_label = label_map[pred_idx]
        pred_conf = probs_percent[pred_idx]

        # ë°œê¸‰ì¼ì
        today = datetime.today().strftime("%Y-%m-%d")

        # --- ì§„ë‹¨ì„œ ì¹´ë“œ ì¶œë ¥ ---
        st.markdown(
            f"""
            <div style="
                border: 2px solid #4CAF50;
                border-radius: 10px;
                padding: 20px;
                background-color: #f9fff9;
                font-family: Arial, sans-serif;
                ">
                <h2 style="color:#2E7D32; text-align:center;">ğŸ§¾ ì¸ê³µì§€ëŠ¥ ì˜ˆì¸¡ ì§„ë‹¨ì„œ</h2>
                <p><b>ë°œê¸‰ì¼ì</b>: {today}</p>
                <p><b>í™˜ì ì§„ìˆ </b>: {user_input}</p>
                <hr>
                <h3 style="color:#1565C0;">ìµœì¢… ì˜ˆì¸¡ ì§„ë‹¨</h3>
                <p style="font-size:22px; font-weight:bold; color:#D32F2F;">
                    {pred_label} ({pred_conf:.1f}%)
                </p>
                <hr>
                <h3 style="color:#1565C0;">ì „ì²´ ì˜ˆì¸¡ í™•ë¥ </h3>
                <ul>
                    <li>{label_map[0]}: <b>{probs_percent[0]:.1f}%</b></li>
                    <li>{label_map[1]}: <b>{probs_percent[1]:.1f}%</b></li>
                    <li>{label_map[2]}: <b>{probs_percent[2]:.1f}%</b></li>
                </ul>
            </div>
            """,
            unsafe_allow_html=True
        )

        st.success("âœ… ì˜ˆì¸¡ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ê²°ê³¼ëŠ” ì°¸ê³ ìš©ì´ë©°, ì¤‘ë“±ë„ ìš°ìš¸ì¦ì¼ ê²½ìš° ì „ë¬¸ì˜ ìƒë‹´ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        # LLM ê¸°ë°˜ ì„¤ëª… ìƒì„± ë° í‘œì‹œ
        explanation_text = generate_llm_explanation(user_input, pred_label)
        st.markdown("### AI ì„¤ëª…")
        st.write(explanation_text)


st.markdown("#  Additional information")
st.markdown("* Patent title : APPARATUS AND METHOD FOR PREDICTING DEPRESSION LEVELS USING NATURAL LANGUAGE PROCESSING AND EXPLAINABLE ARTIFICIAL INTELLIGENCE")
st.markdown("* Patent number :10-2024-0119065")
st.markdown("* Developer: Myung-Gwan Kim")
st.markdown("* Applicant: CHA University Industry-Academic Cooperation Foundation")
st.markdown("* Inventors: Myung-Gwan Kim, Hyun Wook Han, DaWoon Wang, JoonHo Park")









